# Portfolio
---
## Data Extraction & Processing

### IDX Financial Report Extractor
<div>
<img src="https://img.shields.io/badge/Python-3776AB.svg?style=plastic&logo=Python&logoColor=white" alt="Python">
<img src="https://img.shields.io/badge/Data%20Extraction-008080.svg?style=plastic&logo=Power%20Automate&logoColor=white" alt="Automation">
<img src="https://img.shields.io/badge/Web%20Scraping-008080.svg?style=plastic&logo=web&logoColor=white" alt="Web Scraping">
<img src="https://img.shields.io/badge/Finance-008080.svg?style=plastic&logo=Google%20Finance&logoColor=white" alt="Finance">
</div>
<div style="line-height:30%;">
    <br>
</div>

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Rachdyan/idx_financial_report) 

<div style="text-align: justify">
This project provides a Python tool to automate the scraping of raw financial data from the Indonesia Stock Exchange (IDX). It eliminates tedious manual data collection for investors, analysts, and researchers by delivering the information in a ready-to-use Excel format for immediate analysis. See result examples <a href="https://github.com/Rachdyan/idx_financial_report/tree/main/result">here</a>.
</div>

<div style="line-height:50%;">
    <br>
</div>

<center><img src="images/financial_report_example0.png"/></center> 
<center><span style='font-size:30px;'>&#8595;</span></center>
<center><img src="images/financial_report_example1.png"/></center>   

---
### IDX Company Disclosure Summarizer
<div>
    <img src="https://img.shields.io/badge/Python-3776AB.svg?style=plastic&logo=Python&logoColor=white" alt="Python">
    <img src="https://img.shields.io/badge/Web%20Scraping-008080.svg?style=plastic&logo=web&logoColor=white" alt="Web Scraping">
    <img src="https://img.shields.io/badge/AI-008080.svg?style=plastic&logo=Power%20Automate&logoColor=white" alt="AI">
    <img src="https://img.shields.io/badge/Natural%20Languange%20Processing-008080.svg?style=plastic&logo=Google%20Finance&logoColor=white" alt="Automation">
</div>

<div style="line-height:30%;">
    <br>
</div>

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Rachdyan/ktbknidx) 

<div style="text-align: justify">
This project automates intelligence gathering from the Indonesia Stock Exchange (IDX). It continuously monitors for new company disclosures every few hours, uses AI to generate concise summaries of the documents, and delivers these key insights directly to users via a Telegram Bot. This provides a timely source for trading ideas and allows for rapid analysis of market-moving news.
</div>
<br>

<center><img src="images/ktbknidx1.png"/></center> 
<center><span style='font-size:30px;'>&#8595;</span></center>
<center><img src="images/ktbknidx2.png"/></center>   


---
### Facebook Marketplace Deals Finder
<div>
<img src="https://img.shields.io/badge/Python-3776AB.svg?style=plastic&logo=Python&logoColor=white" alt="Python">
<img src="https://img.shields.io/badge/Web%20Scraping-008080.svg?style=plastic&logo=web&logoColor=white" alt="Web Scraping">
<img src="https://img.shields.io/badge/Automation-008080.svg?style=plastic&logo=Google%20Finance&logoColor=white" alt="Automation">
<img src="https://img.shields.io/badge/Data%20Extraction-008080.svg?style=plastic&logo=Power%20Automate&logoColor=white" alt="Automation">
</div>

<div style="line-height:30%;">
    <br>
</div>

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Rachdyan/ktbknidx) 

<div style="text-align: justify">
Tired of manually refreshing Facebook Marketplace and missing out on the best bargains? This project deploys a sophisticated automated tool to hunt for deals on your behalf. It leverages advanced techniques to programmatically handle 2FA logins and bypass CAPTCHA challenges, ensuring consistent, uninterrupted access to the platform. Once running, the tool monitors the marketplace daily for products matching your predefined criteria and price range, instantly forwarding new deals to you via a Telegram bot.
</div>

<br>

<center><img src="images/fb1.png"/></center> 
<center><span style='font-size:30px;'>&#8595;</span></center>
<center><img src="images/fb0.png"/></center>   


---
### Geoscience Job Hunter Bot
<div>
<img src="https://img.shields.io/badge/Python-3776AB.svg?style=plastic&logo=Python&logoColor=white" alt="Python">
<img src="https://img.shields.io/badge/Telegram%20Bot-008080.svg?style=plastic&logo=Power%20Automate&logoColor=white" alt="Telegram Bot">
<img src="https://img.shields.io/badge/Web%20Scraping-008080.svg?style=plastic&logo=web&logoColor=white" alt="Web Scraping">
<img src="https://img.shields.io/badge/Automation-008080.svg?style=plastic&logo=Google%20Finance&logoColor=white" alt="Automation">
</div>

<div style="line-height:30%;">
    <br>
</div>

[![View on Telegram](https://img.shields.io/badge/Telegram-2CA5E0?logo=telegram&logoColor=white)](https://t.me/lokergeo)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Rachdyan/geosains_job_bot)

<div style="text-align: justify">This tool automates the job hunt for geoscientists by scraping top job boards like Indeed, LinkedIn, and Jobstreet for relevant roles. It then consolidates all openings in geology, geophysics, and engineering, and broadcasts them to the dedicated Loker Geosains Telegram channel.</div>
<br>
<center><img src="images/lokergeosains.png"/></center>
<br>

---

### Extract Africa Senior High Schools Report From Unstructured PDF
<div>
<img src="https://img.shields.io/badge/R-%23276DC3.svg?style=plastic&logo=R&logoColor=white" alt="R">
<img src="https://img.shields.io/badge/PDF%20Parsing-008080.svg?style=plastic&logo=Power%20Automate&logoColor=white" alt="PDF Parsing">
<img src="https://img.shields.io/badge/Data%20Extraction-008080.svg?style=plastic&logo=web&logoColor=white" alt="Web Scraping">
</div>


<div style="line-height:30%;">
    <br>
</div>

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Rachdyan/african-shs-data-extraction)

<div style="text-align: justify">
This R project automates the extraction of data on African Senior High Schools from complex PDF files published by <a href="https://africaeducationwatch.org/emis-data-shs-reports">Africa Education Watch</a>. Using the pdftools and tabulizer libraries, it parses the unstructured reports and outputs the information into clean Excel spreadsheets, ready for analysis.
</div>
<br>
<center><img src="images/shs0.png"/></center> 
<center><span style='font-size:30px;'>&#8595;</span></center>
<center><img src="images/shs1.png"/></center>   

---

### USA Labor Condition Application (LCA) Disclosures Data Cleaning
<div>
<img src="https://img.shields.io/badge/R-%23276DC3.svg?style=plastic&logo=R&logoColor=white" alt="R">
<img src="https://img.shields.io/badge/Data%20Cleaning-008080.svg?style=plastic&logo=Power%20Automate&logoColor=white" alt="Data Cleaning">
<img src="https://img.shields.io/badge/Data%20Extraction-008080.svg?style=plastic&logo=web&logoColor=white" alt="Web Scraping">
</div>


<div style="line-height:30%;">
    <br>
</div>

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/Rachdyan/african-shs-data-extraction)

<div style="text-align: justify">
This project transforms raw LCA disclosure data from the <a href="https://www.dol.gov/agencies/eta/foreign-labor/performance">U.S. Department of Labor</a> into a high-quality, actionable dataset. It standardizes employer names by removing legal suffixes, uses fuzzy matching to fix typos in company and contact information, and filters out contacts with generic or personal emails to isolate key decision-makers. The final output is a clean, de-duplicated list of companies and their contacts, complete with aggregated summaries of their total visa filings.
</div>
<br>
<center><img src="images/lca.png"/></center> 

---

## Data Dashboard & Application

### Credit Risk Prediction Web App

[![Open Web App](https://img.shields.io/badge/Heroku-Open_Web_App-blue?logo=Heroku)](http://credit-risk.herokuapp.com/)
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/chriskhanhtran/credit-risk-prediction/blob/master/documents/Notebook.ipynb)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/credit-risk-prediction)

<div style="text-align: justify">After my team preprocessed a dataset of 10K credit applications and built machine learning models to predict credit default risk, I built an interactive user interface with Streamlit and hosted the web app on Heroku server.</div>
<br>
<center><img src="images/credit-risk-webapp.png"/></center>
<br>

---
### Kaggle Competition: Predict Ames House Price using Lasso, Ridge, XGBoost and LightGBM

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/ames-house-price.html)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/kaggle-house-price/blob/master/ames-house-price.ipynb)

<div style="text-align: justify">I performed comprehensive EDA to understand important variables, handled missing values, outliers, performed feature engineering, and ensembled machine learning models to predict house prices. My best model had Mean Absolute Error (MAE) of 12293.919, ranking <b>95/15502</b>, approximately <b>top 0.6%</b> in the Kaggle leaderboard.</div>
<br>
<center><img src="images/ames-house-price.jpg"/></center>
<br>

---
### Predict Breast Cancer with RF, PCA and SVM using Python

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/breast-cancer.html)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/predict-breast-cancer-with-rf-pca-svm/blob/master/breast-cancer.ipynb)

<div style="text-align: justify">In this project I am going to perform comprehensive EDA on the breast cancer dataset, then transform the data using Principal Components Analysis (PCA) and use Support Vector Machine (SVM) model to predict whether a patient has breast cancer.</div>
<br>
<center><img src="images/breast-cancer.png"/></center>
<br>

---
### Business Analytics Conference 2018: How is NYC's Government Using Money?

[![Open Research Poster](https://img.shields.io/badge/PDF-Open_Research_Poster-blue?logo=adobe-acrobat-reader&logoColor=white)](pdf/bac2018.pdf)

<div style="text-align: justify">In three-month research and a two-day hackathon, I led a team of four students to discover insights from 6 million records of NYC and Boston government spending data sets and won runner-up prize for the best research poster out of 18 participating colleges.</div>
<br>
<center><img src="images/bac2018.JPG"/></center>
<br>

---
## Filmed by me

[![View My Films](https://img.shields.io/badge/YouTube-View_My_Films-grey?logo=youtube&labelColor=FF0000)](https://www.youtube.com/watch?v=vfZwdEWgUPE)

<div style="text-align: justify">Besides Data Science, I also have a great passion for photography and videography. Below is a list of films I documented to retain beautiful memories of places I traveled to and amazing people I met on the way.</div>
<br>

- [Ada Von Weiss - You Regret (Winter at Niagara)](https://www.youtube.com/watch?v=-5esqvmPnHI)
- [The Weight We Carry is Love - TORONTO](https://www.youtube.com/watch?v=vfZwdEWgUPE)
- [In America - Boston 2017](https://www.youtube.com/watch?v=YdXufiebgyc)
- [In America - We Call This Place Our Home (Massachusetts)](https://www.youtube.com/watch?v=jzfcM_iO0FU)

---
<center>© 2020 Khanh Tran. Powered by Jekyll and the Minimal Theme.</center>
